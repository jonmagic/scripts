#!/usr/bin/env ruby

# bin/github-conversations-research-agent: Multi-turn research agent for GitHub conversations
#
# This script implements a research workflow that:
# 1. Takes a natural language request and performs initial semantic search
# 2. Generates clarifying questions and opens them in $EDITOR
# 3. Performs iterative deep research based on clarifications
# 4. Produces a final well-formatted Markdown report citing all sources
#
# Usage: github-conversations-research-agent "REQUEST" --collection COLLECTION [options]
#
# Options:
#   --collection NAME        Qdrant collection name (required)
#   -n, --limit N           Max results per search (default: 10)
#   --max-depth N           Max deep-research passes (default: 10)
#   --editor-file PATH      Use fixed file instead of Tempfile
#   --clarifying-qa PATH    Path to file with clarifying Q&A to bypass interactive step
#   --verbose               Show debug logs
#   --fast-model MODEL      Fast LLM model for light reasoning
#   --reasoning-model MODEL Reasoning LLM model for complex analysis
#   --search-mode MODE      Override search mode (semantic, keyword, or hybrid - default: hybrid)
#   --cache-path PATH       Root path for caching fetched data
#
# The script uses the existing bin/semantic-search-github-conversations and
# bin/fetch-github-conversation scripts to gather context, and integrates
# with the llm CLI for AI-powered analysis.

require "json"
require "logger"
require "open3"
require "optparse"
require "tempfile"
require "shellwords"

# Load vendored Pocketflow library
require_relative "../lib/pocketflow"

# Load GitHub Deep Research Agent modules
require_relative "../lib/utils"
require_relative "../lib/github_deep_research_agent/end_node"
require_relative "../lib/github_deep_research_agent/final_report_node"
require_relative "../lib/github_deep_research_agent/claim_verifier_node"
require_relative "../lib/github_deep_research_agent/context_compaction_node"
require_relative "../lib/github_deep_research_agent/retriever_node"
require_relative "../lib/github_deep_research_agent/planner_node"

# Set up global logger
LOG = Logger.new($stdout)
LOG.level = Logger::INFO  # Default level, will be changed to DEBUG with --verbose

# === Embedded Prompt Templates ===

ASK_CLARIFY_PROMPT = <<~PROMPT
You are an expert analyst reviewing a research request and initial findings from GitHub conversations.

## Research Request
{{request}}

## Initial Findings Summary
{{initial_findings}}

Based on the question and initial findings, generate up to 4 clarifying questions that would help you better understand the intent of the request, bridge gaps in context to better refine the search (e.g. specifying the search space like a github organization or repository), and understand the expected output format (executive summary, detailed analysis, ADR, etc). If any of these areas are covered in their request or initial findings, do not ask about them.

Format your response as a numbered list with clear, specific questions. Each question should be on its own line starting with a number. The instructions should ask for inline answers to these questions.
PROMPT

# === Pocketflow Nodes ===

class InitialResearchNode < Pocketflow::Node
  def prep(shared)
    @shared = shared # Store shared context for use in exec
    LOG.info "=== INITIAL RESEARCH PHASE ==="
    LOG.info "Starting initial semantic search for: #{shared[:request]}"
    LOG.debug "Collection: #{shared[:collection]}"
    LOG.debug "Max results: #{shared[:top_k]}"

    request = shared[:request]
    collection = shared[:collection]
    top_k = shared[:top_k]
    script_dir = shared[:script_dir]

    # Extract qualifiers from the initial request for semantic search
    semantic_query_info = Utils.build_semantic_query(request)
    LOG.debug "Extracted semantic query: '#{semantic_query_info[:semantic_query]}'"
    LOG.debug "Extracted repo filter: #{semantic_query_info[:repo_filter]}" if semantic_query_info[:repo_filter]
    LOG.debug "Extracted author filter: #{semantic_query_info[:author_filter]}" if semantic_query_info[:author_filter]

    # Build search plan with extracted qualifiers
    search_plan = semantic_query_info.merge({ query: request })

    # Run semantic search with qualifier extraction
    search_cmd = Utils.build_semantic_search_command(search_plan, script_dir, collection, top_k)
    LOG.debug "Running search command: #{search_cmd}"

    search_output = Utils.run_cmd(search_cmd)
    search_results = JSON.parse(search_output)

    LOG.info "Found #{search_results.length} initial results"
    # LOG.debug example: showing detailed search results when verbose logging is enabled
    LOG.debug do
      result_details = search_results.map.with_index do |result, i|
        "  #{i + 1}. URL: #{result.dig('payload', 'url')}\n" \
        "     Score: #{result['score']}\n" \
        "     Summary: #{result.dig('payload', 'summary')&.slice(0, 100)}..."
      end.join("\n\n")
      "Initial search results:\n#{result_details}"
    end

    search_results
  end

  def exec(search_results)
    LOG.info "Fetching detailed conversation data for #{search_results.length} results..."

    # Fetch detailed conversation data for each result
    enriched_results = []

    search_results.each_with_index do |result, i|
      url = result.dig("payload", "url")
      next unless url

      LOG.debug "Fetching details for result #{i + 1}/#{search_results.length}: #{url}"

      begin
        fetch_cmd = "#{@shared[:script_dir]}/fetch-github-conversation"
        if @shared[:cache_path]
          fetch_cmd += " --cache-path #{Shellwords.escape(@shared[:cache_path])}"
        end
        fetch_cmd += " #{Shellwords.escape(url)}"

        conversation_json = Utils.run_cmd_safe(fetch_cmd)
        conversation_data = JSON.parse(conversation_json)

        metadata = Utils.extract_conversation_metadata(conversation_data)

        LOG.debug do
          "✓ Successfully fetched: #{metadata[:title]}\n" \
          "  Type: #{metadata[:type]}\n" \
          "  State: #{metadata[:state]}\n" \
          "  Comments: #{metadata[:comments_count]}"
        end

        enriched_results << {
          url: url,
          summary: result.dig("payload", "summary") || "",
          score: result["score"],
          conversation: conversation_data
        }
      rescue => e
        LOG.warn "Failed to fetch #{url}: #{e.message}"
      end
    end

    LOG.info "Successfully enriched #{enriched_results.length}/#{search_results.length} conversations"
    enriched_results
  end

  def post(shared, prep_res, exec_res)
    shared[:memory] ||= {}
    shared[:memory][:hits] = exec_res
    shared[:memory][:notes] = []
    shared[:memory][:search_queries] = [shared[:request]]

    LOG.info "✓ Initial research complete: #{exec_res.length} conversations collected"
    LOG.debug "Moving to clarifying questions phase..."

    nil
  end
end

class AskClarifyingNode < Pocketflow::Node
  def prep(shared)
    @shared = shared # Store shared context
    LOG.info "=== CLARIFYING QUESTIONS PHASE ==="
    LOG.info "Generating clarifying questions based on initial findings..."

    # Summarize initial findings
    initial_findings = shared[:memory][:hits].map do |hit|
      "- #{hit[:url]}: #{hit[:summary]}"
    end.join("\n")

    LOG.debug do
      "Initial findings summary:\n#{initial_findings}"
    end

    # Fill template and call LLM
    prompt = Utils.fill_template(ASK_CLARIFY_PROMPT, {
      request: shared[:request],
      initial_findings: initial_findings
    })

    LOG.debug "Calling LLM to generate clarifying questions..."
    # Use fast model for clarifying questions - this is light reasoning to generate questions based on initial findings
    llm_response = Utils.call_llm(prompt, shared[:models][:fast])

    LOG.info "Generated clarifying questions for user review"
    LOG.debug do
      "Generated questions:\n#{'=' * 60}\n#{llm_response}\n#{'=' * 60}"
    end

    llm_response
  end

  def exec(clarifying_questions)
    # Check if we have a pre-written Q&A file to bypass interactive step
    if @shared[:clarifying_qa]
      LOG.info "Using pre-written clarifying Q&A from file: #{@shared[:clarifying_qa]}"

      unless File.exist?(@shared[:clarifying_qa])
        abort "Error: Clarifying Q&A file not found: #{@shared[:clarifying_qa]}"
      end

      edited_content = File.read(@shared[:clarifying_qa])
      LOG.debug do
        "Pre-written clarifications:\n#{'=' * 60}\n#{edited_content}\n#{'=' * 60}"
      end

      return edited_content
    end

    LOG.info "Opening editor for user to answer clarifying questions..."

    # Prepare editor content
    editor_content = <<~CONTENT
Please review the following questions and provide inline answers to help focus the research:

#{clarifying_questions}
CONTENT

    # Open editor
    edited_content = Utils.edit_text(editor_content, @shared[:editor_file])

    LOG.info "User provided clarifications"
    LOG.debug do
      "User clarifications:\n#{'=' * 60}\n#{edited_content}\n#{'=' * 60}"
    end

    edited_content
  end

  def post(shared, prep_res, exec_res)
    shared[:clarifications] = exec_res
    LOG.info "✓ Clarifications collected, proceeding to planning phase"
    LOG.debug "Moving to planning phase..."

    nil
  end
end

# === Main Script ===

# Parse command-line options
options = {
  collection: nil,
  limit: 5,
  max_depth: 2,
  editor_file: nil,
  clarifying_qa: nil,
  verbose: false,
  fast_model: ENV["FAST_LLM_MODEL"],
  reasoning_model: ENV["LLM_MODEL"],
  search_mode: "hybrid",
  cache_path: nil,
  executive_summary_prompt_path: nil
}

opt_parser = OptionParser.new do |opts|
  opts.banner = "Usage: #{File.basename($0)} \"REQUEST\" --collection COLLECTION [options]"

  opts.on("--collection NAME", "Qdrant collection name (required)") do |v|
    options[:collection] = v
  end

  opts.on("-n", "--limit N", Integer, "Max results per search (default: 10)") do |v|
    options[:limit] = v
  end

  opts.on("--max-depth N", Integer, "Max deep-research passes (default: 10)") do |v|
    options[:max_depth] = v
  end

  opts.on("--editor-file PATH", "Use fixed file instead of Tempfile") do |v|
    options[:editor_file] = v
  end

  opts.on("--clarifying-qa PATH", "Path to file with clarifying Q&A to bypass interactive step") do |v|
    options[:clarifying_qa] = v
  end

  opts.on("--verbose", "Show debug logs") do
    options[:verbose] = true
  end

  opts.on("--fast-model MODEL", "Fast LLM model for light reasoning (default: ENV['FAST_LLM_MODEL'] or llm default)") do |v|
    options[:fast_model] = v
  end

  opts.on("--reasoning-model MODEL", "Reasoning LLM model for complex analysis (default: ENV['LLM_MODEL'] or llm default)") do |v|
    options[:reasoning_model] = v
  end

  opts.on("--search-mode MODE", ["semantic", "keyword", "hybrid"], "Override search mode (semantic, keyword, or hybrid - default: hybrid)") do |v|
    options[:search_mode] = v
  end

  opts.on("--cache-path PATH", "Root path for caching fetched data") do |v|
    options[:cache_path] = v
  end

  opts.on("--executive-summary-prompt-path PATH", "Path to LLM prompt file for executive summary generation") do |v|
    options[:executive_summary_prompt_path] = v
  end

  opts.on("-h", "--help", "Show this help message") do
    puts opts
    exit
  end
end

begin
  opt_parser.parse!
rescue OptionParser::InvalidOption => e
  abort "#{e.message}\n\n#{opt_parser}"
end

# Set logger level based on verbose flag
LOG.level = options[:verbose] ? Logger::DEBUG : Logger::INFO

# Validate required arguments
if ARGV.empty?
  abort opt_parser.to_s
end

request = ARGV.join(" ")

if request.strip.empty?
  abort "Error: Empty request provided"
end

unless options[:collection]
  abort "Error: --collection is required\n\n#{opt_parser}"
end

# Set up shared context
script_dir = File.expand_path(File.dirname(__FILE__))

shared = {
  request: request,
  collection: options[:collection],
  top_k: options[:limit],
  max_depth: options[:max_depth],
  editor_file: options[:editor_file],
  clarifying_qa: options[:clarifying_qa],
  verbose: options[:verbose],
  search_mode: options[:search_mode],
  cache_path: options[:cache_path],
  executive_summary_prompt_path: options[:executive_summary_prompt_path],
  models: {
    fast: options[:fast_model],
    reasoning: options[:reasoning_model]
  },
  script_dir: script_dir
}

# Build the workflow
initial_node = InitialResearchNode.new
clarify_node = AskClarifyingNode.new
planner_node = GitHubDeepResearchAgent::PlannerNode.new
retriever_node = GitHubDeepResearchAgent::RetrieverNode.new
compaction_node = GitHubDeepResearchAgent::ContextCompactionNode.new
claim_verifier_node = GitHubDeepResearchAgent::ClaimVerifierNode.new
final_node = GitHubDeepResearchAgent::FinalReportNode.new
end_node = GitHubDeepResearchAgent::EndNode.new

# Link the nodes
initial_node.next(clarify_node)
clarify_node.next(planner_node)
planner_node.next(retriever_node)
retriever_node.on("continue", planner_node) # Loop back to planner for next iteration
retriever_node.on("final", final_node)

# Add claim verification flow
final_node.on("verify", claim_verifier_node)  # Route to claim verification after draft report
final_node.on("complete", end_node)           # Route to clean termination
claim_verifier_node.on("ok", final_node)     # Continue to final output after verification
claim_verifier_node.on("fix", planner_node)  # Route back to planner to gather evidence for unsupported claims

# Add compaction handling
final_node.on("compact", compaction_node)         # Route to compaction when context too large
compaction_node.on("retry", final_node)          # Retry final report after compaction
compaction_node.on("proceed_anyway", final_node) # Proceed with minimal context if compaction fails

# Set end node as the final termination point
final_node.next(end_node)

# Create and run the flow
flow = Pocketflow::Flow.new(initial_node)

begin
  LOG.info "=== GITHUB CONVERSATIONS RESEARCH AGENT ==="
  LOG.info "Request: #{request}"
  LOG.info "Collection: #{options[:collection]}"
  LOG.info "Max results per search: #{options[:limit]}"
  LOG.info "Max deep research iterations: #{options[:max_depth]}"
  LOG.info "Fast model: #{shared[:models][:fast] || 'default'}"
  LOG.info "Reasoning model: #{shared[:models][:reasoning] || 'default'}"

  flow.run(shared)
rescue Interrupt
  LOG.error "\nResearch interrupted by user"
  exit 1
rescue => e
  LOG.error "Error: #{e.message}"
  LOG.debug e.backtrace.join("\n") if shared[:verbose]
  exit 1
end
